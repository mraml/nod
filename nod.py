"""
nod: AI Spec Compliance Gatekeeper

A platform-agnostic, rule-based linter that ensures AI/LLM specifications
contain critical security and compliance elements before automated development.
"""

import argparse
import hashlib
import json
import os
import re
import ssl  # Added for strict security
import sys
import urllib.request
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, Union

import yaml


class Nod:
    """
    The agnostic gatekeeper for AI Spec Compliance.
    Designed to be a 'Policy-as-Code' layer.
    """

    SEVERITY_MAP: Dict[str, int] = {
        "CRITICAL": 4,
        "HIGH": 3,
        "MEDIUM": 2,
        "LOW": 1,
        "INFO": 0,
    }

    SARIF_LEVEL_MAP: Dict[str, str] = {
        "CRITICAL": "error",
        "HIGH": "error",
        "MEDIUM": "warning",
        "LOW": "note",
        "INFO": "note",
    }

    # Security Constants
    DEFAULT_TIMEOUT = 15.0  # seconds for network requests
    MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB limit for spec files to prevent DoS

    def __init__(self, rules_sources: List[str], ignore_path: str = ".nodignore") -> None:
        """
        Initialize the scanner with multiple rule sources and ignore definitions.
        """
        self.rules_sources = rules_sources
        self.config = self._load_and_merge_rules(rules_sources)
        self.policy_version = self.config.get("version", "unknown")
        self.ignored_rules = self._load_ignore_file(ignore_path)
        self.attestation: Dict[str, Any] = {}

    def _load_and_merge_rules(self, sources: List[str]) -> Dict[str, Any]:
        """Loads and stacks multiple rule files. Later files override earlier ones."""
        merged_config = {"profiles": {}, "version": "combined"}
        
        # Security Hardening: Enforce strict SSL verification for remote rules
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = True
        ssl_context.verify_mode = ssl.CERT_REQUIRED
        
        for source in sources:
            try:
                if source.startswith(("http://", "https://")):
                    # Pass the strict context and timeout to urlopen
                    with urllib.request.urlopen(source, context=ssl_context, timeout=self.DEFAULT_TIMEOUT) as response:
                        data = yaml.safe_load(response.read())
                else:
                    # Check local file size before reading config
                    if os.path.exists(source) and os.path.getsize(source) > self.MAX_FILE_SIZE:
                        print(f"Error: Rules file {source} exceeds size limit.")
                        sys.exit(1)
                        
                    with open(source, "r", encoding="utf-8") as f:
                        data = yaml.safe_load(f)
                
                if not data: continue
                
                # Simple deep merge for profiles
                for profile, content in data.get("profiles", {}).items():
                    if profile not in merged_config["profiles"]:
                        merged_config["profiles"][profile] = content
                    else:
                        target = merged_config["profiles"][profile]
                        target.update(content)
                        
            except Exception as e:
                print(f"Error loading rules from {source}: {str(e)}")
                sys.exit(1)
        return merged_config

    def _load_ignore_file(self, path: str) -> List[str]:
        """Loads a list of ignored rule IDs from a .nodignore file."""
        ignored = []
        if os.path.exists(path):
            try:
                # Sanity check size for ignore file
                if os.path.getsize(path) > 1024 * 1024:  # 1MB limit for ignore file
                    print(f"Warning: .nodignore is unusually large, skipping.")
                    return []

                with open(path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith("#"):
                            ignored.append(line)
            except Exception as e:
                print(f"Warning: Could not read ignore file {path}: {e}")
        return ignored

    def _get_line_number(self, content: str, index: int) -> int:
        """Calculates line number from character index."""
        return content.count("\n", 0, index) + 1

    def generate_template(self) -> str:
        """Generates a Markdown template based on the loaded rules."""
        lines = ["# AI Project Specification (Generated by nod)", ""]
        lines.append(f"> Policy Version: {self.policy_version}")
        lines.append("> Auto-generated based on compliance requirements.\n")

        profiles = self.config.get("profiles", {})
        for profile_name, profile_data in profiles.items():
            label = profile_data.get("badge_label", profile_name)
            lines.append(f"---")
            lines.append(f"## Compliance Profile: {label}\n")

            for req in profile_data.get("requirements", []):
                item_id = req["id"]
                remediation = req.get("remediation", "Fill in this section.")
                header_text = re.sub(r"[#+*?^$\[\](){}|]", "", item_id).strip()
                header_text = header_text.replace(".*", " ").replace(".", " ")
                
                lines.append(f"### {header_text}")
                lines.append(f"<!-- {remediation} -->")
                lines.append("TODO: Add details here...\n")

        return "\n".join(lines)

    def generate_system_context(self) -> str:
        """Generates a System Prompt / Context block for AI Agents."""
        lines = ["# SYSTEM COMPLIANCE CONSTRAINTS"]
        lines.append(f"POLICY VERSION: {self.policy_version}")
        lines.append("The following constraints are MANDATORY.\n")

        profiles = self.config.get("profiles", {})
        for profile_name, profile_data in profiles.items():
            label = profile_data.get("badge_label", profile_name)
            reqs = [r for r in profile_data.get("requirements", []) if r["id"] not in self.ignored_rules]
            flags = [f for f in profile_data.get("red_flags", []) if f["pattern"] not in self.ignored_rules]

            if not reqs and not flags: continue

            lines.append(f"## PROFILE: {label}")
            if reqs:
                lines.append("### MUST INCLUDE:")
                for r in reqs:
                    clean_id = re.sub(r"[#+*?^$\[\](){}|]", "", r["id"]).strip()
                    lines.append(f"- {clean_id}: {r.get('remediation', '')}")
            if flags:
                lines.append("### FORBIDDEN:")
                for f in flags:
                    lines.append(f"- PATTERN '{f['pattern']}': {f.get('remediation', '')}")
            lines.append("")

        return "\n".join(lines)

    def scan_file(
        self, file_path: str, strict: bool = False
    ) -> Tuple[Dict[str, Any], str]:
        """Scans a file against the loaded compliance rules."""
        if not os.path.exists(file_path):
            return {"error": f"File not found: {file_path}"}, "NONE"

        _, ext = os.path.splitext(file_path)
        ext = ext.lower()

        try:
            # Resource Protection: Check file size before reading to avoid Memory Exhaustion (DoS)
            file_stats = os.stat(file_path)
            if file_stats.st_size > self.MAX_FILE_SIZE:
                return {"error": f"File too large: {file_path} exceeds {self.MAX_FILE_SIZE/1024/1024}MB limit"}, "NONE"

            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                file_hash = hashlib.sha256(content.encode()).hexdigest()
        except Exception as e:
            return {"error": f"Could not read file: {str(e)}"}, "NONE"

        results = self._audit_logic(content, ext, strict, os.path.dirname(file_path))

        max_sev_value = -1
        max_sev_label = "NONE"
        
        for p in results.values():
            if "checks" in p:
                for c in p["checks"]:
                    if not c["passed"] and c["status"] == "FAIL":
                        val = self.SEVERITY_MAP.get(c["severity"], 0)
                        if val > max_sev_value:
                            max_sev_value = val
                            max_sev_label = c["severity"]

        self.attestation = {
            "tool": "nod",
            "tool_version": "1.5.0",
            "policy_version": self.policy_version,
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "file_audited": file_path,
            "file_sha256": file_hash,
            "max_severity_gap": max_sev_label,
            "results": results,
            "remediation_summary": self._generate_agent_prompt(results),
        }

        return results, max_sev_label

    def _verify_local_evidence(self, content: str, base_dir: str) -> List[Dict[str, Any]]:
        """Checks if local file paths referenced in the spec actually exist."""
        evidence_checks = []
        links = re.finditer(r"\[([^\]]+)\]\((?!http)([^)]+)\)", content)
        
        for match in links:
            text = match.group(1)
            path = match.group(2).strip()
            if path.startswith("#"): continue
            
            full_path = os.path.join(base_dir, path)
            exists = os.path.exists(full_path)
            
            evidence_checks.append({
                "id": f"Evidence: {text}",
                "passed": exists,
                "status": "PASS" if exists else "FAIL",
                "severity": "MEDIUM",
                "type": "evidence_check",
                "remediation": f"Referenced file not found: {path}",
                "line": self._get_line_number(content, match.start())
            })
        return evidence_checks

    def _audit_logic(
        self, content: str, ext: str, strict: bool, base_dir: str
    ) -> Dict[str, Any]:
        """Core logic handling conditions, exceptions, and checks."""
        report = {}
        profiles = self.config.get("profiles", {})

        for profile, profile_data in profiles.items():
            checks = []
            
            # 0. Check Conditional Logic
            skipped_rules = []
            conditions = profile_data.get("conditions", [])
            for cond in conditions:
                if "if" in cond and "regex_match" in cond["if"]:
                    pattern = cond["if"]["regex_match"]
                    try:
                        if re.search(pattern, content, re.IGNORECASE | re.MULTILINE):
                            if "then" in cond and "skip" in cond["then"]:
                                skipped_rules.extend(cond["then"]["skip"])
                    except re.error:
                        # Gracefully handle bad regex in rules file
                        print(f"Warning: Invalid regex in condition: {pattern}")

            # 1. Requirements Scanning
            for req in profile_data.get("requirements", []):
                item_id = req["id"]
                sev = req.get("severity", "HIGH").upper()
                line_num = 1
                status = "FAIL"
                passed = False

                is_exception = item_id in self.ignored_rules
                is_skipped = item_id in skipped_rules

                if is_skipped:
                    status = "SKIPPED"
                    passed = True
                elif is_exception:
                    status = "EXCEPTION"
                    passed = True
                else:
                    if ext == ".json":
                        try:
                            data = json.loads(content)
                            if item_id in data:
                                passed = True
                                status = "PASS"
                                if strict and not str(data[item_id]).strip():
                                    passed = False
                                    status = "FAIL"
                        except json.JSONDecodeError: pass
                    else:
                        try:
                            match = re.search(item_id, content, re.IGNORECASE | re.MULTILINE)
                            if match:
                                passed = True
                                status = "PASS"
                                line_num = self._get_line_number(content, match.start())
                                if strict:
                                    start_index = match.end()
                                    following_text = content[start_index:].split("#")[0].strip()
                                    if len(following_text) <= 15:
                                        passed = False
                                        status = "FAIL"
                        except re.error:
                            print(f"Warning: Invalid regex pattern in rule: {item_id}")
                            status = "FAIL" # Fail closed on bad regex

                checks.append({
                    "id": item_id,
                    "passed": passed,
                    "status": status,
                    "severity": sev,
                    "tags": req.get("tags", []),
                    "remediation": req.get("remediation"),
                    "template_url": req.get("template_url"),
                    "line": line_num
                })

            # 2. Red-Flag Scanning
            for flag in profile_data.get("red_flags", []):
                item_id = flag["pattern"]
                sev = flag.get("severity", "CRITICAL").upper()
                line_num = 1
                status = "PASS"
                passed = True

                try:
                    found = re.search(item_id, content, re.IGNORECASE | re.MULTILINE)
                    if found:
                        line_num = self._get_line_number(content, found.start())
                        if item_id in self.ignored_rules: status = "EXCEPTION"
                        elif item_id in skipped_rules: status = "SKIPPED"
                        else:
                            status = "FAIL"
                            passed = False
                except re.error:
                    print(f"Warning: Invalid regex pattern in red flag: {item_id}")
                    # If red flag pattern is broken, we assume safety (pass) but warn user
                    # Alternatively could fail closed, but false positives are annoying here.

                checks.append({
                    "id": item_id,
                    "passed": passed,
                    "status": status,
                    "severity": sev,
                    "type": "red_flag",
                    "tags": flag.get("tags", ["Security", "Prohibited"]),
                    "remediation": flag.get("remediation"),
                    "line": line_num
                })
            
            # 3. Evidence Verification (Only run if profile enabled)
            if strict and ext != ".json":
                if "security" in profile.lower() or "baseline" in profile.lower():
                    checks.extend(self._verify_local_evidence(content, base_dir))

            blocking_failures = [
                c for c in checks
                if c["status"] == "FAIL" and self.SEVERITY_MAP.get(c["severity"], 0) >= 3
            ]

            report[profile] = {
                "label": profile_data.get("badge_label", profile),
                "checks": checks,
                "passed": len(blocking_failures) == 0,
            }
        return report

    def _generate_agent_prompt(self, results: Dict[str, Any]) -> str:
        """Helper to create a concise summary for agentic resolution."""
        gaps = []
        for p in results.values():
            if "checks" in p:
                for c in p["checks"]:
                    if c["status"] == "FAIL":
                        tags_str = f"[{', '.join(c.get('tags', []))}]" if c.get('tags') else ""
                        gaps.append(
                            f"- [{c['severity']}] {c['id']} {tags_str}: {c.get('remediation', '')}"
                        )
        return "\n".join(gaps) if gaps else "No gaps detected."

    def generate_sarif(self, file_path: str) -> Dict[str, Any]:
        """Generates a SARIF report from the attestation data."""
        rules = []
        results = []
        rule_indices = {}

        for profile_name, profile_data in self.attestation["results"].items():
            for check in profile_data["checks"]:
                rule_id = check["id"]
                if rule_id not in rule_indices:
                    rule_indices[rule_id] = len(rules)
                    sarif_rule = {
                        "id": rule_id,
                        "name": rule_id,
                        "shortDescription": {"text": check.get("remediation", rule_id)},
                        "properties": {"severity": check["severity"], "tags": check.get("tags", [])}
                    }
                    if check.get("template_url"): sarif_rule["helpUri"] = check["template_url"]
                    rules.append(sarif_rule)

                if check["status"] == "FAIL":
                    level = self.SARIF_LEVEL_MAP.get(check["severity"], "warning")
                    result = {
                        "ruleId": rule_id,
                        "ruleIndex": rule_indices[rule_id],
                        "level": level,
                        "message": {"text": f"Gap: {check.get('remediation', 'Missing')}"},
                        "locations": [{
                            "physicalLocation": {
                                "artifactLocation": {"uri": file_path},
                                "region": {"startLine": check.get("line", 1)}
                            }
                        }]
                    }
                    results.append(result)
                elif check["status"] == "EXCEPTION":
                    result = {
                        "ruleId": rule_id,
                        "ruleIndex": rule_indices[rule_id],
                        "level": "note",
                        "kind": "review",
                        "suppressions": [{"kind": "external"}],
                        "message": {"text": "Exception via .nodignore"},
                        "locations": [{"physicalLocation": {"artifactLocation": {"uri": file_path}, "region": {"startLine": check.get("line", 1)}}}]
                    }
                    results.append(result)

        return {
            "version": "2.1.0",
            "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
            "runs": [{"tool": {"driver": {"name": "nod", "version": self.attestation.get("tool_version"), "rules": rules}}, "results": results}]
        }


def main() -> None:
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(description="nod: AI Spec Compliance Gatekeeper")
    parser.add_argument("file", nargs="?", help="The spec file to audit")
    
    parser.add_argument(
        "--rules",
        action='append',
        help="Local path or remote URL for rules. Can be used multiple times.",
    )
    
    parser.add_argument("--init", action="store_true", help="Generate template")
    parser.add_argument("--export", action="store_true", help="Export context")
    parser.add_argument("--strict", action="store_true", help="Ensure fields are not empty")
    parser.add_argument("--min-severity", default="HIGH", choices=["MEDIUM", "HIGH", "CRITICAL"])
    parser.add_argument("--output", choices=["text", "json", "sarif"], default="text")
    args = parser.parse_args()

    # Default to local rules.yaml if no rules provided
    rule_sources = args.rules if args.rules else ["rules.yaml"]
    scanner = Nod(rule_sources)

    if args.export:
        print(scanner.generate_system_context())
        sys.exit(0)

    if args.init:
        template = scanner.generate_template()
        if args.file:
            try:
                with open(args.file, "w", encoding="utf-8") as f:
                    f.write(template)
                print(f"‚úÖ Generated compliant spec template: {args.file}")
                sys.exit(0)
            except IOError as e:
                print(f"Error writing template: {e}")
                sys.exit(1)
        else:
            print(template)
            sys.exit(0)

    if not args.file:
        parser.print_help()
        sys.exit(1)

    results, max_sev = scanner.scan_file(args.file, strict=args.strict)

    if args.output == "sarif":
        sarif_data = scanner.generate_sarif(args.file)
        print(json.dumps(sarif_data, indent=2))
        sys.exit(0 if scanner.SEVERITY_MAP.get(max_sev, 0) < scanner.SEVERITY_MAP.get(args.min_severity) else 1)

    if args.output == "json":
        print(json.dumps(scanner.attestation, indent=2))
        sys.exit(0 if scanner.SEVERITY_MAP.get(max_sev, 0) < scanner.SEVERITY_MAP.get(args.min_severity) else 1)

    print(f"\n--- nod Audit Summary ---")
    print(f"File: {args.file}")
    print(f"Policy Version: {scanner.policy_version}")
    print(f"Max Severity Gap: {max_sev}")
    print(f"--------------------------")

    failed_gate = False
    min_val = scanner.SEVERITY_MAP.get(args.min_severity)

    if "error" in results:
        print(f"Error: {results['error']}")
        sys.exit(1)

    for profile, data in results.items():
        print(f"\n[{data['label']}]")
        for check in data["checks"]:
            if check["status"] == "FAIL":
                icon = "üö©" if check.get("type") == "red_flag" else "‚ùå"
                print(f"  {icon} [{check['severity']}] {check['id']}")
                if check.get("tags"): print(f"     Tags: {', '.join(check['tags'])}")
                print(f"     Remediation: {check.get('remediation', 'None')}")
                if scanner.SEVERITY_MAP.get(check["severity"], 0) >= min_val:
                    failed_gate = True
            elif check["status"] == "EXCEPTION":
                print(f"  ‚ö™ [EXCEPTION] {check['id']} (via .nodignore)")
            elif check["status"] == "SKIPPED":
                print(f"  ‚è≠Ô∏è  [SKIPPED] {check['id']} (Condition met)")
            else:
                pass_tags = f" ({', '.join(check['tags'])})" if check.get("tags") else ""
                print(f"  ‚úÖ [PASS] {check['id']}{pass_tags}")

    try:
        with open("nod-attestation.json", "w", encoding="utf-8") as f:
            json.dump(scanner.attestation, f, indent=2)
    except IOError as e:
        print(f"Warning: Could not save attestation artifact: {e}")

    if failed_gate:
        print(f"\nFAIL: Build blocked due to {args.min_severity}+ severity gaps.")
        sys.exit(1)
    else:
        print(f"\nPASS: Final nod of approval granted.")
        sys.exit(0)


if __name__ == "__main__":
    main()
