"""
nod: AI Spec Compliance Gatekeeper

A platform-agnostic, rule-based linter that ensures AI/LLM specifications
contain critical security and compliance elements before automated development.
"""

import argparse
import hashlib
import hmac
import json
import os
import re
import ssl
import sys
import urllib.request
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, Union

import yaml


class Nod:
    """
    The agnostic gatekeeper for AI Spec Compliance.
    Designed to be a 'Policy-as-Code' layer.
    """

    SEVERITY_MAP: Dict[str, int] = {
        "CRITICAL": 4, "HIGH": 3, "MEDIUM": 2, "LOW": 1, "INFO": 0
    }

    SARIF_LEVEL_MAP: Dict[str, str] = {
        "CRITICAL": "error", "HIGH": "error", "MEDIUM": "warning",
        "LOW": "note", "INFO": "note"
    }

    DEFAULT_TIMEOUT = 15.0
    MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB
    MAX_TOTAL_SIZE = 20 * 1024 * 1024  # 20MB

    def __init__(self, rules_sources: List[str], ignore_path: str = ".nodignore") -> None:
        self.rules_sources = rules_sources
        self.config = self._load_and_merge_rules(rules_sources)
        self.policy_version = self.config.get("version", "unknown")
        self.ignored_rules = self._load_ignore_file(ignore_path)
        self.attestation: Dict[str, Any] = {}

    def _load_and_merge_rules(self, sources: List[str]) -> Dict[str, Any]:
        merged = {"profiles": {}, "version": "combined"}
        ctx = ssl.create_default_context()
        ctx.check_hostname = True
        ctx.verify_mode = ssl.CERT_REQUIRED

        def merge(new_data):
            if not new_data: return
            for k, v in new_data.get("profiles", {}).items():
                if k not in merged["profiles"]: merged["profiles"][k] = v
                else: merged["profiles"][k].update(v)

        for src in sources:
            try:
                if src.startswith(("http://", "https://")):
                    with urllib.request.urlopen(src, context=ctx, timeout=self.DEFAULT_TIMEOUT) as r:
                        merge(yaml.safe_load(r.read()))
                elif os.path.isdir(src):
                    for f in sorted(os.listdir(src)):
                        if f.lower().endswith(('.yaml', '.yml')):
                            fp = os.path.join(src, f)
                            if os.path.getsize(fp) <= self.MAX_FILE_SIZE:
                                with open(fp, "r", encoding="utf-8") as f_in: merge(yaml.safe_load(f_in))
                elif os.path.exists(src):
                    if os.path.getsize(src) <= self.MAX_FILE_SIZE:
                        with open(src, "r", encoding="utf-8") as f: merge(yaml.safe_load(f))
                    else: print(f"Error: {src} exceeds size limit.")
            except Exception as e:
                print(f"Error loading rules from {src}: {str(e)}"); sys.exit(1)
        return merged

    def _load_ignore_file(self, path: str) -> List[str]:
        if os.path.exists(path):
            try:
                if os.path.getsize(path) <= 1024 * 1024:
                    with open(path, "r", encoding="utf-8") as f:
                        return [line.strip() for line in f if line.strip() and not line.startswith("#")]
            except Exception: pass
        return []

    def _get_line_number(self, content: str, index: int) -> int:
        return content.count("\n", 0, index) + 1

    def _clean_header(self, text: str) -> str:
        text = re.sub(r"[#+*?^$\[\](){}|]", "", text).strip()
        return " ".join(text.replace(".*", " ").replace(".", " ").split())

    def _resolve_source(self, content: str, index: int, default_source: str = None) -> str:
        if default_source: return default_source
        markers = list(re.finditer(r"<!-- SOURCE: (.*?) -->", content))
        best = "unknown"
        for m in markers:
            if m.start() < index: best = m.group(1)
            else: break
        return best

    def generate_template(self) -> str:
        lines = ["# AI Project Specification (Generated by nod)", "", f"> Policy Version: {self.policy_version}", "> Auto-generated based on compliance requirements.\n"]
        for name, data in self.config.get("profiles", {}).items():
            lines.append(f"---\n## Compliance Profile: {data.get('badge_label', name)}\n")
            for req in data.get("requirements", []):
                lines.append(f"### {self._clean_header(req['id'])}")
                lines.append(f"<!-- {req.get('remediation', 'Fill in this section.')} -->")
                if req.get("must_contain"):
                    lines.append("<!-- Required subsections: -->")
                    for item in req["must_contain"]: lines.append(f"{item}")
                lines.append("TODO: Add details here...\n")
        return "\n".join(lines)

    def generate_system_context(self) -> str:
        lines = ["# SYSTEM COMPLIANCE CONSTRAINTS", f"POLICY VERSION: {self.policy_version}", "The following constraints are MANDATORY.\n"]
        for name, data in self.config.get("profiles", {}).items():
            reqs = [r for r in data.get("requirements", []) if r["id"] not in self.ignored_rules]
            flags = [f for f in data.get("red_flags", []) if f["pattern"] not in self.ignored_rules]
            if not reqs and not flags: continue
            lines.append(f"## PROFILE: {data.get('badge_label', name)}")
            if reqs:
                lines.append("### MUST INCLUDE:")
                for r in reqs:
                    det = r.get('remediation', '')
                    if r.get("must_contain"): det += f" (Must also contain: {', '.join(r['must_contain'])})"
                    lines.append(f"- {self._clean_header(r['id'])}: {det}")
            if flags:
                lines.append("### FORBIDDEN:")
                for f in flags: lines.append(f"- PATTERN '{f['pattern']}': {f.get('remediation', '')}")
            lines.append("")
        return "\n".join(lines)

    def _collect_files(self, path: str) -> List[str]:
        if os.path.isfile(path): return [path]
        found = []
        for root, dirs, files in os.walk(path):
            dirs[:] = [d for d in dirs if not d.startswith('.')]
            for f in files:
                if os.path.splitext(f)[1].lower() in {'.md', '.markdown', '.json', '.txt'}:
                    found.append(os.path.join(root, f))
        return found

    def scan_input(self, input_path: str, strict: bool = False) -> Tuple[Dict[str, Any], str]:
        target_files = self._collect_files(input_path)
        if not target_files: return {"error": f"No spec files found in {input_path}"}, "NONE"

        agg_content, total_size, file_hashes = "", 0, []
        file_contents = {}
        base_dir = input_path if os.path.isdir(input_path) else os.path.dirname(input_path)
        is_single_json = len(target_files) == 1 and target_files[0].endswith(".json")
        default_source = target_files[0] if is_single_json else None

        for fpath in target_files:
            try:
                size = os.path.getsize(fpath)
                if size > self.MAX_FILE_SIZE: continue
                total_size += size
                if total_size > self.MAX_TOTAL_SIZE: return {"error": "Total aggregation size exceeds memory limit"}, "NONE"
                with open(fpath, "r", encoding="utf-8") as f:
                    raw = f.read()
                    file_contents[fpath] = raw
                    file_hashes.append(hashlib.sha256(raw.encode()).hexdigest())
                    agg_content += raw if is_single_json else f"\n\n<!-- SOURCE: {fpath} -->\n{raw}"
            except Exception as e: print(f"Warning: {e}")

        agg_hash = hashlib.sha256("".join(sorted(file_hashes)).encode()).hexdigest()
        ext = ".json" if is_single_json else ".md"
        results = self._audit_logic(agg_content, ext, strict, base_dir, default_source, file_contents)
        
        max_sev, max_label = -1, "NONE"
        for p in results.values():
            for c in p.get("checks", []):
                if not c["passed"] and c["status"] == "FAIL":
                    val = self.SEVERITY_MAP.get(c["severity"], 0)
                    if val > max_sev: max_sev, max_label = val, c["severity"]

        self.attestation = {
            "tool": "nod", "version": "1.7.0", "policy_version": self.policy_version,
            "timestamp": datetime.utcnow().isoformat() + "Z", "files_audited": target_files,
            "aggregate_hash": agg_hash, "max_severity_gap": max_label, "results": results,
            "remediation_summary": self._generate_agent_prompt(results),
        }
        self._sign_attestation()
        return results, max_label

    def _sign_attestation(self):
        secret = os.environ.get("NOD_SECRET_KEY")
        if secret:
            payload = f"{self.attestation['aggregate_hash']}|{self.attestation['timestamp']}|{self.attestation['max_severity_gap']}"
            self.attestation["signature"] = hmac.new(secret.encode(), payload.encode(), hashlib.sha256).hexdigest()
            self.attestation["signed"] = True
        else: self.attestation["signed"] = False

    def _verify_local_evidence(self, content: str, base_dir: str, default_source: str = None) -> List[Dict[str, Any]]:
        checks = []
        for m in re.finditer(r"\[([^\]]+)\]\((?!http)([^)]+)\)", content):
            path = m.group(2).strip()
            if path.startswith("#"): continue
            exists = os.path.exists(os.path.join(base_dir, path))
            checks.append({
                "id": f"Evidence: {m.group(1)}", "passed": exists, "status": "PASS" if exists else "FAIL",
                "severity": "MEDIUM", "type": "evidence", "remediation": f"File not found: {path}",
                "line": 1, "source": self._resolve_source(content, m.start(), default_source)
            })
        return checks

    def _check_req(self, content: str, ext: str, req: Dict, strict: bool) -> Tuple[bool, int, int, str]:
        # Returns: passed, line, match_start, error_message
        item_id = req["id"]
        passed = False
        line = 1
        start_idx = -1
        err = ""

        if ext == ".json":
            try:
                data = json.loads(content)
                if item_id in data:
                    val = str(data[item_id])
                    if not strict or val.strip():
                        passed = True
                        for p in req.get("must_match", []):
                            if p.get("pattern") and not re.search(p["pattern"], val, re.IGNORECASE | re.MULTILINE):
                                passed = False
                                err = p.get('message', 'Value mismatch')
            except: pass
        else:
            try:
                m = re.search(item_id, content, re.IGNORECASE | re.MULTILINE)
                if m:
                    start_idx = m.start()
                    line = self._get_line_number(content, start_idx)
                    passed = True
                    
                    match_str, end = m.group(0).strip(), m.end()
                    lvl = len(match_str) - len(match_str.lstrip('#')) if match_str.startswith('#') else 0
                    section = content[end:]
                    next_pat = r"^#{1," + str(lvl) + r"}\s" if lvl > 0 else r"^#+\s"
                    next_m = re.search(next_pat, section, re.MULTILINE)
                    if next_m: section = section[:next_m.start()]

                    if strict and len(section.strip()) <= 15: passed = False
                    
                    if passed:
                        missing = [sub for sub in req.get("must_contain", []) if not re.search(re.escape(sub), section, re.IGNORECASE)]
                        if missing: passed, err = False, f"Missing: {', '.join(missing)}"
                    
                    if passed:
                        for p in req.get("must_match", []):
                            if p.get("pattern") and not re.search(p["pattern"], section, re.IGNORECASE | re.MULTILINE):
                                passed, err = False, f"{p.get('message', 'Pattern mismatch')}"
            except re.error: pass
        
        return passed, line, start_idx, err

    def _audit_logic(self, content: str, ext: str, strict: bool, base_dir: str, default_source: str = None, file_map: Dict[str, str] = None) -> Dict[str, Any]:
        report = {}
        for profile, p_data in self.config.get("profiles", {}).items():
            checks, skipped, added_reqs = [], [], []
            
            for cond in p_data.get("conditions", []):
                if "regex_match" in cond.get("if", {}):
                    try:
                        if re.search(cond["if"]["regex_match"], content, re.IGNORECASE | re.MULTILINE):
                            skipped.extend(cond.get("then", {}).get("skip", []))
                            for r in cond.get("then", {}).get("require", []):
                                if isinstance(r, str): added_reqs.append({"id": r, "severity": "HIGH", "remediation": f"Triggered by condition: {cond['if']['regex_match']}"})
                                elif isinstance(r, dict): added_reqs.append(r)
                    except re.error: pass

            for req in p_data.get("requirements", []) + added_reqs:
                item_id, status, passed, line, source = req["id"], "FAIL", False, 1, default_source
                remediation = req.get("remediation", "")
                mode = req.get("mode", "at_least_one")
                
                if item_id in skipped: status, passed = "SKIPPED", True
                elif item_id in self.ignored_rules: status, passed = "EXCEPTION", True
                else:
                    if mode == "in_all_files" and file_map:
                        # Check strictly in EVERY file
                        missing_files = []
                        for fpath, fcontent in file_map.items():
                            fext = os.path.splitext(fpath)[1].lower()
                            p, _, _, _ = self._check_req(fcontent, fext, req, strict)
                            if not p: missing_files.append(os.path.basename(fpath))
                        
                        if missing_files:
                            status, passed = "FAIL", False
                            remediation = f"Missing in {len(missing_files)} files: {', '.join(missing_files)}. " + remediation
                        else:
                            status, passed, source = "PASS", True, "all_files"
                    else:
                        # Default: Check aggregate (at least one)
                        p, l, s_idx, err = self._check_req(content, ext, req, strict)
                        if p:
                            status, passed, line = "PASS", True, l
                            if not source and s_idx >= 0: source = self._resolve_source(content, s_idx)
                        if err: remediation = f"{err}. " + remediation

                checks.append({
                    "id": item_id, "passed": passed, "status": status, 
                    "severity": req.get("severity", "HIGH").upper(),
                    "remediation": remediation, "tags": req.get("tags", []), "article": req.get("article"),
                    "control_id": req.get("control_id"), "source": source, "line": line
                })

            for flag in p_data.get("red_flags", []):
                item_id, status, passed, line, source = flag["pattern"], "PASS", True, 1, default_source
                try:
                    m = re.search(item_id, content, re.IGNORECASE | re.MULTILINE)
                    if m:
                        line = self._get_line_number(content, m.start())
                        if not source: source = self._resolve_source(content, m.start())
                        if item_id in self.ignored_rules: status = "EXCEPTION"
                        elif item_id in skipped: status = "SKIPPED"
                        else: status, passed = "FAIL", False
                except re.error: pass
                checks.append({
                    "id": item_id, "passed": passed, "status": status, "severity": flag.get("severity", "CRITICAL").upper(),
                    "type": "red_flag", "remediation": flag.get("remediation"), "tags": flag.get("tags", []),
                    "article": flag.get("article"), "control_id": flag.get("control_id"), "source": source, "line": line
                })

            if strict and ext != ".json" and ("security" in profile or "baseline" in profile):
                checks.extend(self._verify_local_evidence(content, base_dir, default_source))

            blocking = [c for c in checks if c["status"] == "FAIL" and self.SEVERITY_MAP.get(c["severity"], 0) >= 3]
            report[profile] = {"label": p_data.get("badge_label", profile), "checks": checks, "passed": len(blocking) == 0}
        return report

    def _generate_agent_prompt(self, results: Dict[str, Any]) -> str:
        gaps = []
        for p in results.values():
            for c in p.get("checks", []):
                if c["status"] == "FAIL":
                    ref = c.get("control_id") or c.get("article") or ""
                    gaps.append(f"- [{c['severity']}] {c['id']} {f'[{ref}]' if ref else ''}: {c.get('remediation', '')}")
        return "\n".join(gaps) if gaps else "No gaps detected."

    def apply_fix(self, input_path: str, results: Dict[str, Any]):
        tgt = input_path if os.path.isfile(input_path) else os.path.join(input_path, "nod-compliance.md")
        try:
            with open(tgt, "a", encoding="utf-8") as f:
                f.write("\n\n<!-- nod: auto-fix appended below -->\n")
                cnt = 0
                for name, data in results.items():
                    missing = [c for c in data["checks"] if c["status"] == "FAIL" and c.get("type") != "red_flag"]
                    if not missing: continue
                    f.write(f"\n## Missing: {data['label']}\n")
                    for m in missing:
                        f.write(f"\n### {self._clean_header(m['id'])}\n")
                        if m.get("control_id"): f.write(f"> Ref: {m['control_id']}\n")
                        f.write(f"<!-- {m.get('remediation')} -->\nTODO: Add details here.\n")
                        cnt += 1
            print(f"‚úÖ patched {tgt}: Appended {cnt} missing sections.")
        except Exception as e: print(f"Error patching: {e}")

    def generate_compliance_report(self) -> str:
        lines = []
        for profile, data in self.attestation["results"].items():
            checks = data.get("checks", [])
            compliant = len([c for c in checks if c["status"] != "FAIL"])
            pct = int((compliant / len(checks) * 100) if checks else 0)
            lines.append(f"{data['label']} Compliance Report\nGenerated: {datetime.utcnow().strftime('%Y-%m-%d')}")
            lines.append(f"Status: {pct}% Compliant ({compliant}/{len(checks)} requirements)\n")
            for c in checks:
                icon = {"FAIL": "‚ùå", "EXCEPTION": "‚ö™", "SKIPPED": "‚è≠Ô∏è"}.get(c["status"], "‚úÖ")
                ref = c.get("article") or c.get("control_id")
                lines.append(f"{icon} {f'{ref}: ' if ref else ''}{self._clean_header(c['id'])}")
                if c["status"] == "FAIL": lines.append(f"   Status: MISSING\n   Remediation: {c.get('remediation', '')}")
                elif c["status"] == "PASS":
                    if c.get("source") and c["source"] != "unknown": lines.append(f"   Evidence: {c['source']}:{c.get('line')}")
                else: lines.append(f"   Status: {c['status']}")
                lines.append("")
            lines.append("-" * 40 + "\n")
        return "\n".join(lines)

    def generate_sarif(self, input_path: str) -> Dict[str, Any]:
        rules, results, r_map = [], [], {}
        for p_data in self.attestation["results"].values():
            for c in p_data["checks"]:
                rid = c["id"]
                if rid not in r_map:
                    r_map[rid] = len(rules)
                    props = {"severity": c["severity"], "tags": c.get("tags", [])}
                    if c.get("article"): props["article"] = c["article"]
                    if c.get("control_id"): props["security-severity"] = c["control_id"]
                    rules.append({"id": rid, "name": rid, "shortDescription": {"text": c.get("remediation", rid)}, "properties": props})
                
                uri = c.get("source") if c.get("source") and c.get("source") != "unknown" else input_path
                if c["status"] in ["FAIL", "EXCEPTION"]:
                    lvl = self.SARIF_LEVEL_MAP.get(c["severity"], "warning") if c["status"] == "FAIL" else "note"
                    res = {
                        "ruleId": rid, "ruleIndex": r_map[rid], "level": lvl,
                        "message": {"text": f"Gap: {c.get('remediation')}" if c["status"] == "FAIL" else "Exception via .nodignore"},
                        "locations": [{"physicalLocation": {"artifactLocation": {"uri": uri}, "region": {"startLine": c.get("line", 1)}}}]
                    }
                    if c["status"] == "EXCEPTION": res.update({"kind": "review", "suppressions": [{"kind": "external"}]})
                    results.append(res)
        return {"version": "2.1.0", "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json", "runs": [{"tool": {"driver": {"name": "nod", "version": self.attestation["version"], "rules": rules}}, "results": results}]}

def main() -> None:
    parser = argparse.ArgumentParser(description="nod: AI Spec Compliance Gatekeeper")
    parser.add_argument("path", nargs="?", help="The spec file OR directory to audit")
    parser.add_argument("--rules", action='append', help="Rule sources")
    parser.add_argument("--init", action="store_true", help="Generate template")
    parser.add_argument("--fix", action="store_true", help="Auto-append missing sections")
    parser.add_argument("--export", action="store_true", help="Export context")
    parser.add_argument("--strict", action="store_true", help="Ensure fields are not empty")
    parser.add_argument("--min-severity", default="HIGH", choices=["MEDIUM", "HIGH", "CRITICAL"])
    parser.add_argument("--output", choices=["text", "json", "sarif", "compliance"], default="text")
    args = parser.parse_args()

    defaults = ["defaults"] if os.path.isdir("defaults") else ["rules.yaml"]
    scanner = Nod(args.rules if args.rules else defaults)

    if args.export: print(scanner.generate_system_context()); sys.exit(0)
    if args.init:
        t = scanner.generate_template()
        if args.path:
            if os.path.exists(args.path) and os.path.isfile(args.path): print(f"Error: {args.path} exists."); sys.exit(1)
            with open(args.path, "w", encoding="utf-8") as f: f.write(t)
            print(f"‚úÖ Generated: {args.path}")
        else: print(t)
        sys.exit(0)

    if not args.path: parser.print_help(); sys.exit(1)
    results, max_sev = scanner.scan_input(args.path, strict=args.strict)
    if args.fix: scanner.apply_fix(args.path, results); sys.exit(0)

    if args.output == "sarif": print(json.dumps(scanner.generate_sarif(args.path), indent=2))
    elif args.output == "json": print(json.dumps(scanner.attestation, indent=2))
    elif args.output == "compliance":
        print(scanner.generate_compliance_report())
        sys.exit(0 if scanner.SEVERITY_MAP.get(max_sev, 0) < scanner.SEVERITY_MAP.get(args.min_severity) else 1)
    else:
        print(f"\n--- nod Audit Summary ---\nTarget: {args.path}\nMax Severity Gap: {max_sev}")
        if scanner.attestation.get("signed"): print(f"üîí Signature: VERIFIED (HMAC-SHA256)")
        failed, min_val = False, scanner.SEVERITY_MAP.get(args.min_severity)
        for p in results.values():
            print(f"\n[{p['label']}]")
            for c in p["checks"]:
                if c["status"] == "FAIL":
                    print(f"  ‚ùå [{c['severity']}] {c['id']}")
                    if c.get("source"): print(f"     File: {c['source']}")
                    if c.get("control_id"): print(f"     Ref: {c['control_id']}")
                    if scanner.SEVERITY_MAP.get(c["severity"], 0) >= min_val: failed = True
                elif c["status"] == "EXCEPTION": print(f"  ‚ö™ [EXCEPTION] {c['id']}")
                elif c["status"] == "SKIPPED": print(f"  ‚è≠Ô∏è  [SKIPPED] {c['id']}")
                else: print(f"  ‚úÖ [PASS] {c['id']}")
        
        if failed: print(f"\nFAIL: Blocked by {args.min_severity}+ gaps."); sys.exit(1)
        print("\nPASS: Nod granted."); sys.exit(0)

if __name__ == "__main__":
    main()
